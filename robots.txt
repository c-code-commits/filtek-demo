# robots.txt for Filtrade Website
# This file tells search engines what they can and cannot crawl

User-agent: *
Allow: /

# Sitemap location
Sitemap: https://yourusername.github.io/filtrade-website/sitemap.xml

# Disallow crawling of specific directories if needed
# Disallow: /assets/
# Disallow: /css/
# Disallow: /js/


